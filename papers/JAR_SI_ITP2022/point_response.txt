Dear reviewers.

Thank you for your reviews and useful suggestions to improve the paper.

Please find attached my point-by-point response to your suggestions, of which I have implemented most.
My responses start with # (many of them are just #done, or #fixed)

Summary of main changes:

* replaced link to Isabelle-LLVM homepage on github, added reference to Zenodo-hosted artefact for this paper's version of Isabelle-LLVM.
* added experimental data for old verified algorithm
* added "Development Effort" subsection, with information on LOC and development time
* added paragraph on scalability to future work



#################### Reviewer 1
Review for the article "Refinement of Parallel Algorithms down to LLVM applied to
practically efficient parallel sorting"

The given article of Peter Lammich is an extended version of an earlier ITP 2022
paper. The extensions are clearly indicated in the article, and I fully agree to
their descriptions. In particular, more parts of the overall sorting algorithm
have been parallelized.

(1) A verified parallel partitioning algorithm has been integrated to the
parallel sorting algorithm. This partitioning algorithm is not at all trivial
and required further setup, e.g., by an auxiliary data structures for interval
lists and parallel combinators to support more fine-grained parallel access to
separate parts of the memory.

(2) As a consequence, the efficiency of the verified parallel sorting algorithm
has been improved even further, such that it is competitive to non-verified
algorithms of standard libraries.
  
Indeed, the experimental data w.r.t. (2) is really impressive. To see the diff
w.r.t. the ITP 2022 paper, it would just have been nice to include the
performance of the implementation of the 2022 paper in this article as well. (so
if possible generate diagrams/experimental data with four configurations: 2022
verified, 2023 verified, std:sort, sample sort) 
# Added data for the old algorithm. Except for the small-arrays benchmark, on which we didn't report in the ITP-2022 paper at all, and thus had no data.


Regarding the content of the paper, there is a clear high-level structure that
covers most aspects in the overall workflow to verify parallel programs.
1. Introduction / Isabelle notation
2. Model of LLVM, including memory model, monads, ...
3. Separation logic in the parallel setting, including verification condition 
   generation
4. Refinements for Parallel Programs, with special support for splitting arrays
5. Applications: Parallel Sorting and Parallel Partioning, experiments
6. Conclusion

Because of this completeness, I really enjoyed reading this article from the
beginning to the end. Lammich nicely combines precision of formal definitions
with explanations about how to understand and read the formal text. (Given the
support of the underlying formalization, for some of the more technical
definitions, I could safely just glance over them without checking all details)

Most of the text should become quite clear to a general audience with a formal
background. However, there are certain primitives that might need a bit more
explanation, in particular if one is not an Isabelle/HOL user or if one is not
familiar with LLVM, cf. the detailed comments below.

Overall, I recommend to accept this article after taking into account the
following detailed remarks.


---------------
In the abstract one reads "implemented in C/C++", whereas the last line on page
1 says GNU's C++ and Boost C++: so where is a pure C-implementation? Wouldn't it
be more precise to just drop the C-language in the abstract and just speak of
C++ implementations? 
# done

page 1, last line: Boost C++ Libraries -> Boost C++ libraries (lowercase l in
library as in GNU's C++ std library)
# when used as a name, it's written with capital L on the Boost webpages, so I did the same
  
page 2, first line: ITP 2023 paper -> ITP 2022 paper
# done

page 2: the formalization is available at www21.in.tum.de/ ... given that your
current affiliation is Twente, why use an URL of your old employer? Any plans to
submit the work to AFP for better visibility and archival?
# Submission to AFP is a long-term plan. For now, I have hosted the web-page on github, where I also develop the project, and have archived the release corresponding to this paper on Zenodo. I have added both, the webpage and the link to the artefact, to the paper.

page 2: (VCG). (Section 3).  -> use only one ., e.g., (VCG), cf. Section 3.
# done

page 3: Please add space around inequality signs in "x<4" "x<=4", etc.: "x < 4"
"x <= 4". Also "xs1 @xs2" looks wrong: please put space left and right of @: 
"xs1 @ xs2" 
# Adjusted spacings throughout whole document
  
page 3: "The cardinality of the finite set" -> "The cardinality of a finite set"?
#done

page 4: 'x M == mu => ... neM
   return_M x mu = ...
Here, you use the letter mu both as type and as variable for memories: mu :: mu
(In contrast, for access reports you use r :: rho)
If possible, avoid this overloading, or at least mention it briefly.
# The obvious name m is already used for monads. I added an explanation.
  
page 5-6: you use the type nat for several concepts, e.g., addresses of blocks,
indices within blocks, ...
(datatype addr = ... nat ... nat ...;   acc == ... nat ... nat ... )
perhaps introduce some type-synonyms to disambiguate these concepts
# I have introduced the bidx type for block indexes. The index within a block is never used as explicit type in the rest of the paper, so nothing changed here.
  
page 5, after typedef memory:
Please explain the structure of addresses, too: briefly say what the two indices
are.
# Already done a few lines below. Have expanded the explanation a bit.

page 7: "pointer arithmetic can be performed on that address": 
Previously you said that no pointer arithmetic is supported. (end of Sect. 2.2:
"Note that our LLVM semantics does not support ...") Therefore, this sentence
sounds strange. Please clarify.
# Same as C++, we support pointer arithmetic between pointers to the same block, but not between different blocks. 2.2 states that we do not support: ptr->int and difference of pointers between *different* blocks.
  
page 7: instruction for "a" parallel function call
# done

page 8 and everywhere: please add vertical space before "Example 1/2/3/..."
# I have not altered the default settings. Afaik, this is the intended spacing of the sn-jnl template.

page 8: "The lifting uparrow phi holds iff the Boolean value phi is true."
Then why is the then-branch of the if-then-else not just "true", but "Box"?
# true would mean that the assertion can own arbitrary memory. I explain this by saying "...owning no memory".

  
page 9: by the frame amfis accessed -> add more space after italic amf
# done

page 11: list is a permutation ... mset xs' = mset xs
For non-Isabelle users it is not clear what "mset" is. You did not mention this
in the Isabelle intro, so please once explain that "mset .. = mset .." is
exactly the permutation-condition in Isabelle, expressed via multiset equality.
# added explanation
  
page 12: what is ll_ofs_ptr in aget and aset?
# added: "where \is{ll_ofs_ptr} is the Isabelle-LLVM instruction for offsetting a pointer by an index."

page 14: why did you use fold in ivl_card ls? isn't sum_list [|s| . s <- ls]
a more concise and also more automation-friendly definition? 
(from my experience, working with fold often complicates verification tasks)
# the refinement framework has very good setup for fold. In particular to refine it to a loop for the implementation. Using sum-list (and map) would be more complicated to refine to an efficient imperative implementation.
  
page 15: more direct design, "e.g.," using ...
# done

page 16: Splitting an array into two halves ...: I propose to rename "halves"
into "parts", since the size of each part is not one half (1/2), but can be
arbitrary.
# done
  
page 16: list_all2 and map2 might also need a short explanation to non-Isabelle
users
# added

page 19: we prove the following Hoare-triple for our final implementation: 
This looks really nice!
# thank you

page 20: we use "idx.introsort xs". I guess, a little bit more explanation would
help non-Isabelle users: please explain that introsort has been defined within
the (generic) locale, and because of the the interpretation command, you now
obtain a sorting algorithm for a particular comparison operation with
idx.introsort.
# expanded the explanation

page 21: Please move longish description of Fig. 3 into main text: Currently to
read though the text one has to read until "sketched in Figure 3", then turn
pages to read description of Fig. 3, then continue with next sentence after
"sketched in Figure 3".
# placed Fig3 on correct page

page 23: Could you figure out the reason of why string-sorting is faster
unverified? Is it because of the different representation of strings, cf.
Footnote 7?
# Unfortunately not, we have to leave that to future work. All benchmarked algorithms, verified or not, use the same string implementation.


 
page 26: Before beginning with Section 6.1, I'd like to see a read a bit about
the amount of efforts that went into the various parts. For instance, how much
work (lines of Isabelle) went into the extension to go from sequential to
parallel in the abstract frameworks? How many lines is the verification of
sequential pdqsort, and how many lines did you have to add for the refinement to
parallel-code, ...?
# I have added some statistics in a new "Development Effort" subsection


page 26: When compiling your theories, I noticed that sepref takes quite some
time at certain invocations. Can you say a few words about scalability of your
approach?
# I have added a short section on (improving) scalability to future work, citing our TACAS'23 paper (not yet accepted by date of manuscript submission) which reports on our experience of verifying a whole state-of-the-art SAT solver with Isabelle-LLVM. [Mathias Fleury, Peter Lammich: A More Pragmatic CDCL for IsaSAT and Targetting LLVM (Short Paper). CADE 2023: 207-219]




page 26: is efficient"[32, Sec. 2] -> add blank between " and [32
# DONE

page 27ff: Several references are not correctly displayed, they contain "???".
# fixed




#################### Reviewer 2
Main comments:

This is an excellent extension of an already excellent ITP'23
paper. Apart from various sloppy formatting issues with the maths in
this paper, I think this is ready to be accepted. 

The new content in this journal version is the verified parallel
partitioning algorithm, which is well explained. I particularly liked
Figure 3 which made it very clear how most of the partitioning can be
done in parallel.

Minor comments:

There is a formatting error at "The formalization is available
at". Since this is the first sentence of a new paragraph, the text
should be indented.
# done

The math notation in Sec 1.2 is strangely squished together. For
example, in "x≤4" the less-than-or-eq sign nearly touches the x. I
wonder if some space hack has been applied that removes as much space
in math as possible. I find this really hard to read. The authors must
fix the strange space issue.
# we use the listings package for rendering Isabelle text, which is not particularly good at spacing.
# I have now fixed these and various other spacing issues.

The same problem with spacing appears in Sec 2.1 at "r=x".
# fixed

However, suddenly in Sec 2.2 there are parts where there is too much
space. It seems the math formatting isn't using \mathit{..} around
ADDR and ALLOC, and, as a result, one gets ADDR as almost "A D D R"
and ALLOC as "A L L O C".
# This is the spacing generated by mathit for upper-case letters. Afaik, unless some low-level space hacks are used, upper-case words will always be rendered like this, be it in mathit, or listings, or plain text.


Page 6 has more math spacing issues: "r1∪ r2, w1∪ w2, a1∪ a2, f1∪ f2"
-- why is there no space between the first var and union, but there is
a space between the union and the second variable? There seems to be
many such type setting errors, e.g. "xs1 @xs2" on page 15.
# fixed

The C++ code shown at the bottom of page 7 should probably be in alltt
format to clearly indicate that it isn't math.
# done

I thought "indexes" was a typo, but found out that it's an acceptable
spelling of the plural of index. I would have expected "indices".
# I typically use 'indexes'. Now consistently (there was one 'indices' in the document)

"Only then we used our" 
--> 
"Only then did we use switch to our"
or
"Only then did we use our"
# done

"At this point, one may ask why not directly verify the C++
implementation" -- no change in the text is needed here, but I suspect
it's harder to build abstractions from the C++ code. What I'm trying
to say is that the proof effort would be greater, or at least the
person doing the proofs would have to write a lot more. One might also
need to work with LLVM code generated from the C++ code or rely on a
semantics for a subset of C++ (which sounds daunting to me). My point
is that this text comes across as suggesting working upwards in the
proof might be as much effort, but I don't think so. Top down sounds
like less effort in the proofs (but perhaps not in finding a
performant implementation).
# That's an interesting question. The short answer is that we have nice and usable tools for top-down verification, but not so for bottom-up verification of full-fledged C++. Refraining to a small fragment of C++ would annihilate all the advantages of having a nice and clean program for experimentation. The same holds for LLVM: we have tools to create a fragment of LLVM in an top-down approach, but not to import the complete LLVM fragment used by C++ compilers. Also, the semantic annotations like invariants etc. must be translated if you don't want to loose your mind on re-constructing them from LLVM for bottom-up verification.


missing space "it efficient”[32, Sec. 2]"
# fixed
