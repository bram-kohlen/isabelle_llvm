Overall merit
B.
OK paper, but I will not champion it

Confidence
Y.
I am knowledgeable in this area, but not an expert

Paper summary
The paper presents a technique for generating verified parallel algorithms in LLVM intermediate representation with total correctness guarantees. This is based in the Isabelle Refinement Framework and makes use of a refinement approach:

The user provides a sequential abstract program. This program contains hints for the subsequent refinement steps. For instance, the npar combinator, which executes two blocks sequentially, is a hint to refine to parallel execution. Conversely, nseq is the same as npar, but it is translated to sequential execution.
The Sepref tool then refines the abstract program to a concrete LLVM representation. The authors modified the semantics of LLVM to report the read and written memory locations. This allows defining a parallel combinator that fails whenever there is a data race.
The reasoning infrastructure is based on separation logic. The authors defined a separation algebra, abstraction function from concrete memory to separation algebra, weakest precondition predicate, validity of Hoare triples, and a Verification Condition Generator.
The result is an LLVM parallel program and a refinement proof.

As a case study, the authors verify total correctness for a parallel sorting algorithm. This algorithm is based on a verified sequential version of Introsort and makes use of a verified pdqsort.

Strengths
This paper makes progress towards providing total correctness guarantees for parallel algorithms in the Isabelle Refinement Framework.

Weaknesses
It only discusses one benchmark.
There is no support for read-only shared memory, meaning that only threads that run on disjoint memory can to be executed in parallel. The authors do discuss this as future work.
Explanation of your recommendation and comments to authors
I liked this paper and I think it makes a worthy contribution by taking a step towards providing total correctness guarantees for parallel algorithms. While there are some shortcomings (one single benchmark and no support for shared read-only memory), this paper still makes reasonable progress.

Comments/questions:

It would have been nice to see at least another case study.
For the definition of the parallel combinator, I think that the definition for "conflict a1 a2" is missing an outer negation?
With respect to presentation, I think that discussing a bit more about the refinement process (and Sepref) earlier in the paper could better motivate the formalisation. As it is now, I didn't fully understand the big picture and the aim of all the formalisation until quite late in the paper.
For the performance comparison to the C++ version, I guess ideally you would be using some existing optimised implementation rather than implementing your own. However, I imagine such an implementation doesn't exist. Probably the easiest way is to go the other way around and start from an existing optimised implementation for which you then generate your own LLVM one. That would make for an interesting comparison.
Typos:

page 3: "separation logic 3" --> "separation logic (Section 3)"
page 12: "how to refine this two an actual" --> "how to refine this to an actual"
Questions for authors’ response
In the description of the Sepref tool, you mention that "The synthesis is automatic, but usually requires some program-specific setup and boilerplate". I'm not sure I fully understand what this program-specific setup is. Are you referring to the refinement assertions and hnr rules for the program operations? Do these have to be provided by the user? I would have thought some of them are fairly generic. Could you clarify everything one would have to provide in order for the sorting algorithm to go through?

Review #100B
Overall merit
C.
Weak paper, though I will not fight strongly against it

Confidence
Y.
I am knowledgeable in this area, but not an expert

Paper summary
This submission reports on a formal verification effort of a parallel sorting algorithm employing disjoint parallelism (race free, and moreover, the forked threads never access the same variables). Verification is carried out in a framework for refinement of sequential programs in Isabelle (IRF) using a pre-existing LLVM model in Isabelle. Some extensions of these frameworks are needed, e.g., with a programming construct for disjoint parallelism, and a Hoare rule for it. Successful verification entails (total) correctness of the LLVM code (assuming its formalized semantics is correct). The (only) case study is parallel quick-sort with certain heuristics for preventing small partitions and for picking a good pivots. Verification is done by using a simple abstract parallel program for sorting which lies between the actual implementation and the sequential abstraction.

Strengths
correctness is fully verified in Isabelle/HOL

the verified implementation is not so far from standard real worlds ones

Weaknesses
contribution seems rather narrow given previous work on sequential programs

The main solver Sepref (based on certain heuristics) is not sufficiently clear

The paper is hard to read, composed mostly by Isabelle-style code snippets

Explanation of your recommendation and comments to authors
I was surprised to see that parallel sorting algorithms were not verified in proof assistants before, and I consider this as a useful contribution.

Still, I think that the contribution of this paper is too narrow for ESOP. It only considers one algorithm, and it seems that only small extensions of the existing components were actually needed: including disjoint parallelism construct in LLVM syntax and semantics, standard disjoint parallelism rule in separation logic, extensions of the Sepref tool. The latter part was the not sufficiently clear to me, and I was not convinced it will work for other examples.

I also found the paper very hard to follow, and not sufficiently accessible for ESOP. The technical contents is given mostly as code with sparse explanations. Even well known notations (e.g., for Hoare triples and points-to assertions) are encoded as predicates as in the Isabelle implementation. This makes the paper look like a documentation of the formalization. Standard mathematical definitions and theorems (preferably in textual environments) and standard notations can help to follow the material, and identify what are the new insights in this submission.

Questions for authors’ response
What were the key technical challenges to overcome in this verification effort?

In particular, it is expected that completely disjoint parallelism is captured as a sequential computation. Then, what is needed here beyond syntactic race detection?

Review #100C
Overall merit
D.
Reject

Confidence
X.
I am an expert in this area

Paper summary
Designs a verification condition generator (VCG) based on separation logic for parallel algorithms.
Verifies the total correctness of a parallel sort algorithm.
Translates the parallel sort algorithm to LLVM.
Strengths
Designs a decent VCG for parallel algorithms.
Weaknesses
Overclaims.
The definition of the parallel combinator is dubious (page 5).
The trusted computing base (TCB) is too large.
Explanation of your recommendation and comments to authors
Overclaims.

Page 1 says this paper presents "the first formalization of parallelism for a practically usable LLVM semantics." But the semantics presented in Section 2 is too simple to be called a formalization of LLVM semantics.

Page 2 says this paper presents "the first verification of a parallel sorting algorithm". See Actris: Session-Type Based Reasoning in Separation Logic (POPL 2020).

Page 22 says "total correctness is a non-trivial endeavour that is subject of active research [39]". But it is unfair. [39] indeed provides a way to prove total correctness, and they can prove termination using almost the same idea employed in this paper, i.e., using the decreasing index.

The definition of the parallel combinator is dubious (page 5).

If m1 is NTERM and m2 is FAIL, then the result is NTERM, which is quite wrong because m2 is FAIL. Also, it introduces asymmetry: if m1 and m2 are FAIL and NTERM, respectively, then the result is FAIL.

Identifying NTERM and FAIL is maybe okay for the supposed model of parallelism, where there is no communication, but in the presence of I/O or communication, it is not justified: an NTERM thread may communicate with another thread.

The current definition doesn't support benign races.

The trusted computing base (TCB) is too large.

I think at least:

The underlying separation logic's adequacy should be proved as in Iris [18].
The meaning of Hoare triples should be defined w.r.t. the underlying semantic model as in Iris [18].
The arrA, idxA, sorted, mset functions should be verified.
The translation to LLVM should be verified.
Questions for authors’ response
In my eyes, many of the claimed contributions are actually already made by prior work, for the reasons I describe above. Would you please elaborate on your contributions so that I can better judge this paper?
